{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mlp_classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osXtFBkD6J_Y",
        "colab_type": "text"
      },
      "source": [
        "We'll use SciKit Learn's built in Breast Cancer Data Set which has several features of tumors with a labeled class indicating whether the tumor was Malignant or Benign. We will try to create a neural network model that can take in these features and attempt to predict malignant or benign labels for tumors it has not seen before. Let's go ahead and start by getting the data!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSNvxWpk6MFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "cancer = load_breast_cancer()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHHQ-uav6RKf",
        "colab_type": "text"
      },
      "source": [
        "This object is like a dictionary, it contains a description of the data and the features and targets:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnz79o7n6Rs_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24ea2b46-2763-4b1c-efef-54cf2fbbf09e"
      },
      "source": [
        "cancer.keys()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVHCxqsY6WX6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7858ec88-9e61-4450-b93e-e9c917b7c1e4"
      },
      "source": [
        "# Print full description by running:\n",
        "# print(cancer['DESCR'])\n",
        "# 569 data points with 30 features\n",
        "cancer['data'].shape\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD5WcSmr65Cv",
        "colab_type": "text"
      },
      "source": [
        "Let's set up our Data and our Labels:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAnk93kZ69Uh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = cancer['data']\n",
        "y = cancer['target']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mhU7-kM7CzK",
        "colab_type": "text"
      },
      "source": [
        "Train Test Split\n",
        " \n",
        "Let's split our data into training and testing sets, this is done easily with SciKit Learn's train_test_split function from model_selection:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89AUYmpt7Db5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2kIERY97G-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D57pvq4m7cFg",
        "colab_type": "text"
      },
      "source": [
        "Scaling data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A59qPQQg7foj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60ce543f-223d-4f46-b7bd-0b0eba82b8c1"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "# Fit only to the training data\n",
        "scaler.fit(X_train)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXQYVoPS7f86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now apply the transformations to the data:\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j04axkD67i95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing the MLP classifier model\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlJMdwye78Jl",
        "colab_type": "text"
      },
      "source": [
        "Next we create an instance of the model, there are a lot of parameters you can choose to define and customize here, we will only define the hidden_layer_sizes. For this parameter you pass in a tuple consisting of the number of neurons you want at each layer, where the nth entry in the tuple represents the number of neurons in the nth layer of the MLP model. There are many ways to choose these numbers, but for simplicity we will choose 3 layers with the same number of neurons as there are features in our data set:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKvf4L5Q78k3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "de2a7ded-283e-4637-e6e7-4735cb77963d"
      },
      "source": [
        "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30))\n",
        "\n",
        "#training the model\n",
        "mlp.fit(X_train,y_train)\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(30, 30, 30), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxmrfH8S8Pc9",
        "colab_type": "text"
      },
      "source": [
        "You can see the output that shows the default values of the other parameters in the model. I encourage you to play around with them and discover what effects they have on your model!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAv0F26L8PxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = mlp.predict(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXH7fq5W8TjE",
        "colab_type": "text"
      },
      "source": [
        "Now we can use SciKit-Learn's built in metrics such as a classification report and confusion matrix to evaluate how well our model performed:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PQKPQEa8T-Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "be722bad-6151-4c6b-fd03-6f0ac11db612"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print(confusion_matrix(y_test,predictions))\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[56  1]\n",
            " [ 2 84]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca7uLZR18YLE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "b78ce9d2-f74e-4614-e40e-8b765ad6cabf"
      },
      "source": [
        "print(classification_report(y_test,predictions))\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97        57\n",
            "           1       0.99      0.98      0.98        86\n",
            "\n",
            "    accuracy                           0.98       143\n",
            "   macro avg       0.98      0.98      0.98       143\n",
            "weighted avg       0.98      0.98      0.98       143\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlONdBPb8aJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3aJzm_38gNb",
        "colab_type": "text"
      },
      "source": [
        "Looks like we only misclassified 3 tumors, leaving us with a 98% accuracy rate (as well as 98% precision and recall). This is pretty good considering how few lines of code we had to write! The downside however to using a Multi-Layer Preceptron model is how difficult it is to interpret the model itself. The weights and biases won't be easily interpretable in relation to which features are important to the model itself.\n",
        "\n",
        "However, if you do want to extract the MLP weights and biases after training your model, you use its public attributes coefs_ and intercepts_.\n",
        "\n",
        "coefs_ is a list of weight matrices, where weight matrix at index i represents the weights between layer i and layer i+1.\n",
        "\n",
        "intercepts_ is a list of bias vectors, where the vector at index i represents the bias values added to layer i+1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssreMEt88gb3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}